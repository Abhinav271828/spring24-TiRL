# spring24-TiRL
Notes and resources for the Topics in Reinforcement Learning course at IIIT Hyderabad.

# Course Outline
- [ ] Module 1
    - Motivation
    - Probability
    - Markov Chains
- [ ] Module 2
    - Markov Decision Processes
- [ ] Module 3
    - Introduction to Reinforcement Learning
- [ ] Module 4
    - Advanced Reinforcement Learning


# Lecture Contents
* Lecture 1 (04 Jan, Thu)
    - Introduction
        - Perspectives on RL
            - Markovian Decision Processes
            - Sequential Decision Problems
        - Key Ingredients
            - Transition Model
            - Reward Model
            - Policy
        - Classification of RL Problems
* Lecture 2 (08 Jan, Mon)
    - Probability Theory
        - $\sigma$-algebras as Domains for Probability
        - Conditional Probability
        - Independence & Mutual Exclusivity
        - Random Variable
        - Expectation, Moments, Variance
        - Multiple Random Variables
* Lecture 3 (11 Jan, Thu)
    - Probability Theory (contd.)
        - Sampling from Continuous RVs
        - Convergence of RVs
        - Interchanging Limits and Expectation
* Lecture 4 (18 Jan, Thu)
    - Markov Chains
        - Discrete-Time Markov Chains
        - Chapman-Kolmogorov Equations for DTMC
        - Classification of States
        - Limiting Probabilities
* Lecture 5 (20 Jan, Sat)
    - Markov Chains (contd.)
        - Markov Chains as Recursions
        - Markov Reward Process
        - Deterministic Dynamic Programming
* Lecture 6 (22 Jan, Mon)
    - Markov Chains
        - Deterministic Dynamic Programming (contd.)
        - Stochastic Dynamic Programming
            - Types of Policies
            - Evaluating a Policy
* Lecture 7 (25 Jan, Thu)
    - Markov Chains
        - Stochastic Dynamic Programming
            - Evaluating a Policy (contd.)
            - Subproblems
            - Bellman Optimality Equations
            - Q-Function Formulation
* Lecture 8 (01 Feb, Thu)
    - [MISSED]
* Lecture 9 (05 Feb, Mon)
    - Markov Chains
        - Policy Evaluation
            - Constructing the Optimal Policy
            - Improving a Policy
            - Convergence
* Lecture 10 (08 Feb, Thu)
    - Markov Chains
        - Contraction Mapping
            - Optimality Operator
        - Value Iteration
            - Gaus-Seidel or In-Place Value Iteration
            - Asynchronous Value Iteration
        - Modified Policy Iteration
* Lecture 11 (15 Feb, Thu)
    - Reinforcement Learning
        - Model-Based Learning
        - Model-Free Learning
        - Framework and Notation
    - Model-Free Strategies
        - Policy Evaluation
            - Naive Policy Evaluation
* Lecture 12 (19 Feb, Mon)
    - Model-Free Strategies
        - Policy Evaluation (contd.)
            - First-Visit Policy Evaluation
            - Every-Visit Policy Evaluation
            - Estimates for State-Action Pairs
        - Policy Improvement
            - Monte Carlo Control with Exploring Starts
            - MC Control without Exploring Starts

# Grading Policy
* Quiz-1: 10%
* Midsem: 25%
* Project-1: 25%
* Quiz-2: 10%
* Project-2: 30%